{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr  \n",
    "from collections import OrderedDict\n",
    "\n",
    "# Do not display warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Display whole text in columns\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\jfox\\Desktop\\My Python Projects\\Chrono Analysis\\ClosuresData.csv\", encoding='cp1252')\n",
    "\n",
    "# Preserve a copy of df1 with the original column values for testing later\n",
    "test_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Last10Chronos','CloseType','Gender','Race','Risk','Age','#ArrestsPastYear','ProbationType','DaysOnProbation','EpicsDosagePastYear']].loc[((data['CloseType'] == 'Successful') | (data['CloseType'] == 'Unsuccessful')) & (pd.notnull(data['Last10Chronos']))].rename(columns={'CloseType':'Outcome','Last10Chronos':'Chronos'})\n",
    "\n",
    "# Fill in missing values. This is taken care of in the SQL source, but including here as well just in case.\n",
    "data['Gender'].loc[pd.isnull(data['Gender'])] = 'Other/Unknown'\n",
    "data['Race'].loc[pd.isnull(data['Race'])] = 'Other/Unknown'\n",
    "data['Risk'].loc[pd.isnull(data['Risk'])] = 'Not Assessed'\n",
    "#data['TopCriminogenicNeed'].loc[pd.isnull(data['TopCriminogenicNeed'])] = 'Not Assessed'\n",
    "data['#ArrestsPastYear'].loc[pd.isnull(data['#ArrestsPastYear'])] = 0\n",
    "data['ProbationType'].loc[pd.isnull(data['ProbationType'])] = 'Misdemeanor Probation'\n",
    "data['DaysOnProbation'].loc[pd.isnull(data['DaysOnProbation'])] = 0\n",
    "data['EpicsDosagePastYear'].loc[pd.isnull(data['EpicsDosagePastYear'])] = 0\n",
    "data['EpicsDosagePastYear'] = data['EpicsDosagePastYear'].astype('int64')\n",
    "\n",
    "# Create Age groups\n",
    "data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "data['Age'].fillna(value=data['Age'].mean(), inplace=True)\n",
    "data['AgeGroup'] = round(data.Age//10*10)\n",
    "data = data.drop('Age',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_clean(data, col):\n",
    "\n",
    "    #stop = stopwords.words('english')\n",
    "    stop = text.ENGLISH_STOP_WORDS\n",
    "    \n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    data[col] = data[col].str.lower()\n",
    "    \n",
    "    data[col] = data[col].str.replace(r'\\b[uU]\\b', 'you', regex=True)\n",
    "    data[col] = data[col].str.replace(r\"what's\", \"what is \", regex=True)\n",
    "    data[col] = data[col].str.replace(r\"can't\", \"cannot \", regex=True)\n",
    "    data[col] = data[col].str.replace(r\"i'm\", \"i am \", regex=True)\n",
    "    data[col] = data[col].str.replace(r\"\\'ll\", \" will \", regex=True)\n",
    "    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"[:|♣|'|§|♠|*|/|?|=|%|&|-|#|•|~|^|>|<|►|_]\", ' ', regex=True)\n",
    "    data[col] = data[col].str.replace(r\" w/\", \" with \", regex=True)\n",
    "    data[col] = data[col].str.replace(r\"\\'s\", \" \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" i/c \", \" in custody \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" ct \", \" court \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" cort \", \" court \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" crt \", \" court \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"ov \", \"office visit \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"o/v \", \"office visit \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"ovwd\", \"office visit with defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"hv \", \"home visit \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"h/v \", \"home visit \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"h v \", \" home visit \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" jl \", \" jail \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" ltr \", \" letter \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" vm \", \" voicemail \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" v/m \", \" voicemail \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" msg \", \" message \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"l/m \", \" left message \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"lm \", \" left message \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"l m \", \" left message \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"vm \", \" voicemail \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"v m \", \" voicemail \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" bw \", \" bench warrant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" b/w \", \" bench warrant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" vop \", \" violation of probation \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" returbnd \", \" returned \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" comp \", \" completed \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" att \", \" attempted \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"att \", \"attempted \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"a/v \", \" attempted visit \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"recvd \", \" received \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"recv'd \", \" received \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"rec'd \", \" received \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"recv \", \" received \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"recvd \", \" received \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"t/c \", \" call \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"t c \", \" call \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"tc \", \" call \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"o/c \", \" outgoing call \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" thru \", \" through \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" rpt \", \" report \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" rptd \", \" reported \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" wdef \", \" with defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" d \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"def \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"def. \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" def \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\"deft \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" deft's \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" d's \", \" defendant \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" presemt \", \" present \", regex=True)\n",
    "    data[col] = data[col].str.replace(\" yr \", \" year \", regex=True)\n",
    "\n",
    "\n",
    "    # Remove phrases that imply obvious failure (these won't be in actual data for predictions)\n",
    "    data[col] = data[col].str.replace(\"death\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"passed away\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"deceased\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"closed\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"file close\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"terminated\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"convicted\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"conviction\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"sentenced\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"prison sentence\", \"\", regex=True)\n",
    "    data[col] = data[col].str.replace(\"jail sentence\", \"\", regex=True)\n",
    "\n",
    "\n",
    "    # Remove numbers.\n",
    "    #data[col] = data[col].str.replace(r'\\d', ' ', regex=True)\n",
    "\n",
    "    # Remove more than one whitespace character\n",
    "    data[col] = data[col].str.replace('\\s+', ' ', regex=True)\n",
    "    \n",
    "    # Any string of 3 or more characters are replaced by just 2.\n",
    "    data[col] = data[col].str.replace(r'(.)\\1+', r'\\1\\1', regex=True)\n",
    "    \n",
    "    # Clean some punctutations\n",
    "    data[col] = data[col].str.replace('\\n', ' \\n ', regex=True)\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3', regex=True)\n",
    "    # Punctuations left single s's \n",
    "    data[col] = data[col].str.replace(\" s \", \" \", regex=True)\n",
    "    \n",
    "    # Add space around repeating characters\n",
    "    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ', regex=True)\n",
    "    \n",
    "    # Patterns with repeating characters \n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', regex=True)\n",
    "    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1', regex=True)\n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n",
    "    data[col] = data[col].str.replace(r'[ ]{2,}',' ', regex=True).str.strip()   \n",
    "    \n",
    "    # Lemmatize text\n",
    "    #data[col] = data[col].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split(' ')]))\n",
    "    \n",
    "    # Remove stop words\n",
    "    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "col_clean(data,'Chronos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenly_distribute(df):\n",
    "    df = df.sample(frac=1)\n",
    "    df1 = df[df.apply(lambda x: x['Outcome'] == 'Successful', axis=1)]\n",
    "    df2 = df[df.apply(lambda x: x['Outcome'] == 'Unsuccessful', axis=1)]\n",
    "    if len(df1)>=len(df2):\n",
    "        shrunk = df1[:len(df2)]\n",
    "        return(df2.append(shrunk).sample(frac=1))\n",
    "    else: \n",
    "        shrunk = df2[:len(df1)]\n",
    "        return(df1.append(shrunk).sample(frac=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoder\n",
    "\n",
    "object_cols = [c for c in data.columns if (data[c].dtype == object) and (c != 'Chronos') and (c != 'Outcome')]\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(data[object_cols]), columns=OH_encoder.get_feature_names(object_cols))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = data.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "data = data.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to data\n",
    "data = pd.concat([data, OH_cols_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#ArrestsPastYear': -0.2545355999911566,\n",
       " 'ProbationType_AB109': -0.2374814008420108,\n",
       " 'Risk_High Violent': -0.16495722517381944,\n",
       " 'Gender_Male': -0.10573796024217477,\n",
       " 'Risk_High Property/Violent': -0.07318721165888835,\n",
       " 'Race_Black': -0.04461391729909708,\n",
       " 'Risk_Not Assessed': -0.015984875360306336,\n",
       " 'Race_Other/Unknown': -0.002702597001862766,\n",
       " 'Gender_Other/Unknown': 0.00611130938105452,\n",
       " 'Race_Hispanic/Latin/Mexican': 0.018846860921251825,\n",
       " 'Race_White': 0.02142721016187698,\n",
       " 'Risk_High Drug': 0.02903651347592988,\n",
       " 'EpicsDosagePastYear': 0.048203137011135044,\n",
       " 'AgeGroup': 0.06426452692678342,\n",
       " 'DaysOnProbation': 0.0742383288953944,\n",
       " 'Risk_Moderate': 0.07884377321817809,\n",
       " 'ProbationType_Misdemeanor Probation': 0.10499681974185288,\n",
       " 'Gender_Female': 0.10551970684161845,\n",
       " 'ProbationType_Felony Probation': 0.13400412830814742,\n",
       " 'Risk_Low': 0.15909027473214865}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the Pearson's correlation between variable and outcome, store in dictionary.\n",
    "\n",
    "pcorrelations = {}\n",
    "  \n",
    "for i in [c for c in data.columns if ((data[c].dtype == 'float64') or (data[c].dtype == 'int64')) and (c != 'Chronos') and (c != 'Outcome')]:\n",
    "    corrdata1 = data[i]\n",
    "    corrdata2 = data.Outcome.map({'Successful':1,'Unsuccessful':0})\n",
    "    # calculate Pearson's correlation\n",
    "    corr, _ = pearsonr(corrdata1, corrdata2)\n",
    "    pcorrelations[i] = corr\n",
    "\n",
    "pcorrelations = dict(sorted(pcorrelations.items(), key=lambda item: item[1]))\n",
    "\n",
    "pcorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "# Evenly distribute the training data\n",
    "train = evenly_distribute(train)\n",
    "\n",
    "\n",
    "train_x = train.drop('Outcome', axis=1)\n",
    "train_y = pd.DataFrame(train['Outcome'])\n",
    "\n",
    "test_x = test.drop('Outcome', axis=1)\n",
    "test_y = pd.DataFrame(test['Outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df= 2, max_df = 0.5, analyzer = 'word', ngram_range = (1,4), max_features = 15000)\n",
    "\n",
    "# Vectorize text\n",
    "train_vectors = vectorizer.fit_transform(train_x['Chronos'].values.astype('str'))\n",
    "test_vectors = vectorizer.transform(test_x['Chronos'].values.astype('str'))\n",
    "\n",
    "# Add back to dataframes\n",
    "train_x = pd.concat([train_x,pd.DataFrame(train_vectors.toarray(), columns= vectorizer.get_feature_names()).set_index(train_x.index)], axis=1)\n",
    "test_x = pd.concat([test_x,pd.DataFrame(test_vectors.toarray(), columns= vectorizer.get_feature_names()).set_index(test_x.index)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit model(s).\n",
    "\n",
    "model1 = RidgeClassifier()\n",
    "#model2 = svm.SVC(kernel='linear')\n",
    "#model3 = LogisticRegression()\n",
    "#model4 = KNeighborsClassifier()\n",
    "model5 = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "model1.fit(train_x.drop('Chronos', axis=1),train_y)\n",
    "#model2.fit(train_x.drop('Chronos', axis=1),train_y)\n",
    "#model3.fit(train_x.drop('Chronos', axis=1),train_y)\n",
    "#model4.fit(train_x.drop('Chronos', axis=1),train_y)\n",
    "model5.fit(train_x.drop('Chronos', axis=1),train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1 is:  0.8133333333333334\n",
      "Accuracy of model 5 is:  0.8272463768115942\n"
     ]
    }
   ],
   "source": [
    "# Fit and check accuracy of each model\n",
    "\n",
    "predictions1 = model1.predict(test_x.drop('Chronos', axis=1))\n",
    "#predictions2 = model2.predict(test_x.drop('Chronos', axis=1))\n",
    "#predictions3 = model3.predict(test_x.drop('Chronos', axis=1))\n",
    "#predictions4 = model4.predict(test_x.drop('Chronos', axis=1))\n",
    "predictions5 = model5.predict(test_x.drop('Chronos', axis=1))\n",
    "\n",
    "print('Accuracy of model 1 is: ',accuracy_score(test['Outcome'],predictions1,'\\n'))\n",
    "#print('Accuracy of model 2 is: ',accuracy_score(test['Outcome'],predictions2,'\\n'))\n",
    "#print('Accuracy of model 3 is: ',accuracy_score(test['Outcome'],predictions3,'\\n'))\n",
    "#print('Accuracy of model 4 is: ',accuracy_score(test['Outcome'],predictions4,'\\n'))\n",
    "print('Accuracy of model 5 is: ',accuracy_score(test['Outcome'],predictions5,'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model\n",
    "\n",
    "my_model = RandomForestClassifier(n_estimators=500)\n",
    "test['Predictions'] = predictions5\n",
    "test.to_csv('testpredictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train chosen model on 100% of the data (evenly distributed) and save.\n",
    "\n",
    "model_data = evenly_distribute(data)\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(model_data['Chronos'].values.astype('str'))\n",
    "\n",
    "model_data = pd.concat([model_data.drop('Chronos', axis=1),pd.DataFrame(train_vectors.toarray(), columns= vectorizer.get_feature_names()).set_index(model_data.index)], axis=1)\n",
    "\n",
    "my_model.fit(model_data.drop('Outcome', axis=1),model_data['Outcome'])\n",
    "\n",
    "with open('Success_Model.pkl', 'wb') as f:#\n",
    "    pickle.dump((vectorizer, OH_encoder, my_model), f)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc7fd2cd169a13873ec0959c5e1f77dc18d0db5cd07944da598c5d45a0cdab8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
